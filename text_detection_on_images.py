# -*- coding: utf-8 -*-
"""Text Detection on Images

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bVsVoUhTm5szX3kcEsueQQe5QAvGkpRW
"""

!pip uninstall opencv-python -y
!pip install opencv-python-headless==4.1.2.30

!pip install easyocr

pip install opencv-python

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from easyocr import Reader
import pandas as pd
import cv2
import time

def imshow(title = "Image",image=None,size=10):
    w,h = image.shape[0], image.shape[1]
    aspect_ratio = w/h
    plt.figure(figsize=(size*aspect_ratio, size))
    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
    plt.title(title)
    plt.show()

def clean_text(text):
    return "".join([c if ord(c) < 128 else "" for c in text]).strip()

img = cv2.imread('/content/ocr_test1.jpg')

print("Detecting and Reading the text from input image...")
reader = Reader(["en","ar"], gpu=False)
results = reader.readtext(img)
print(f'Completed')

for (box, text, prob) in results:
    print("[INFO] {:.4f}: {}".format(prob, text))

    (tl, tr, br, bl) = box
    tl = (int(tl[0]), int(tl[1]))
    tr = (int(tr[0]), int(tr[1]))
    br = (int(br[0]), int(br[1]))
    bl = (int(bl[0]), int(bl[1]))

    text = clean_text(text)

    cv2.rectangle(img, tl, br, (255, 0, 0), 2)
    cv2.putText(img, text, (tl[0], tl[1] - 10),
      cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)

imshow("Processed Image", img, size = 12)
print("TEXT: {}".format(text))

pip install pyttsx3

import pyttsx3

engine = pyttsx3.init('sapi5')

voices = engine.getProperty('voices')

engine.setProperty('voices',voices[0].id)

def speak(audio):
    engine.say(audio)
    engine.runAndWait()

speak(text)